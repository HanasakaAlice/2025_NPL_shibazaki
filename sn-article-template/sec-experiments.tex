\chapter{Experiments}\label{ch:exp}

In this chapter, we experimentally evaluate the effectiveness of PU+TRADES (uPU+TRADES and nnPU+TRADES), proposed in Chapter~\ref{ch:method}, on multiple benchmark datasets.
Specifically, we compare our methods with existing approaches using clean accuracy (Clean Accuracy) and adversarial accuracy (Adversarial Accuracy) as evaluation metrics, and also analyze the effect of the TRADES coefficient $\beta$.
Furthermore, we conduct additional experiments to examine how the theoretical threshold on the number of unlabeled samples, derived in Chapter~\ref{ch:theory}, corresponds to empirical observations.

\section{Experiments}
\subsection{Experimental Setup}

% requires: \usepackage{booktabs}
% optional: \usepackage{graphicx}  (if you use resizebox)
\begin{table}[t]
 \centering
  \caption{Experimental settings for each dataset (F-MNIST, CIFAR-10, CIFAR-100, and Alzheimer MRI).}
 \label{tab:exp_settings}
 \vspace{5pt}
 \small
 \setlength{\tabcolsep}{3.5pt} % tighten columns
 \resizebox{\linewidth}{!}{ % <- uncomment if still too wide
 \begin{tabular}{l|cccc}
 \toprule
  \textbf{Item} & \textbf{F-MNIST} & \textbf{CIFAR-10} & \textbf{CIFAR-100} & \textbf{Alzheimer} \\
 \midrule
  Dataset & FashionMNIST & CIFAR-10 & CIFAR-100 & Alzheimer MRI \\
  Positive class & Top (0,2,4,6) & Vehicles (0,1,8,9) & organics & AD patients \\
  \# positive samples $n_p$ & 1{,}000 & 1{,}000 & 1{,}000 & 769 \\
  \# unlabeled samples $n_u$ & 10{,}000 & 10{,}000 & 50{,}000 & 5{,}121 \\
  Class prior $\pi_p$ & 0.4 & 0.4 & 0.5 & 0.5 \\
  Model & 6-layer MLP & ResNet-18 & ResNet-18 & ResNet-50 \\
 \midrule
  % Methods & \multicolumn{4}{c}{uPU, nnPU, uPU-PGD, nnPU-PGD, uPU+TRADES, nnPU+TRADES} \\
  Perturbation budget $\epsilon$ & 0.3 & 0.031 & 0.031 & 0.031 \\
  Step size $\alpha$ & 0.01 & 0.031 & 0.031 & 0.031 \\
  \# PGD iterations & \multicolumn{4}{c}{10 steps} \\
  TRADES coefficient $\beta$ & \multicolumn{4}{c}{6, 12, 18} \\
 \midrule
  Metrics & \multicolumn{4}{c}{Clean Accuracy, Adversarial Accuracy} \\
 \bottomrule
 \end{tabular}
  }
\end{table}

\paragraph{Datasets.}
We conduct evaluation experiments on four benchmark datasets: FashionMNIST (F-MNIST~\cite{Xiao2017FashionMNIST}), CIFAR-10~\cite{krizhevsky2009learning}, CIFAR-100~\cite{krizhevsky2009learning}, and the Alzheimer dataset\footnote{Dubey, S. \textit{Alzheimer's Dataset} (Kaggle).\ \url{https://www.kaggle.com/tourist55/alzheimers-dataset-4-class-of-images}}.
For F-MNIST, we consider clothing-image classification; for CIFAR-10, we focus on identifying vehicle classes; for CIFAR-100, we target \texttt{organics}; and for Alzheimer, we aim at recognizing AD patients.
The definition of the positive class, the number of positive samples $n_{\mathrm{P}}$, the number of unlabeled samples $n_{\mathrm{U}}$, the class prior $\pi_{\mathrm{P}}$, and the model architectures for each dataset are summarized in Table~\ref{tab:exp_settings}.

\paragraph{Evaluation metrics.}
To compare the performance of each method, we report clean accuracy (Clean Accuracy) and adversarial accuracy (Adversarial Accuracy) on the test set.
Accuracy is defined as
\[
\text{Accuracy}=\frac{\text{\# correct predictions}}{\text{\# total samples}}.
\]
Adversarial accuracy is computed as the classification accuracy on adversarial examples generated by PGD; the perturbation budget $\epsilon$, step size $\alpha$, and the number of iterations (10 steps) follow Table~\ref{tab:exp_settings}.

\paragraph{Training details.}
As listed in Table~\ref{tab:exp_settings}, we use a 6-layer MLP~\cite{Goodfellow-et-al-2016} for F-MNIST, ResNet-18~\cite{He2016ResNet} for CIFAR-10/100, and ResNet-50~\cite{He2016ResNet} for Alzheimer.
As baselines, for F-MNIST and CIFAR-10 we use uPU and nnPU, as well as PGD-based adversarial training (uPU-PGD and nnPU-PGD) and TRADES-based adversarial training (uPU+TRADES and nnPU+TRADES).
For CIFAR-100 and Alzheimer, training is unstable due to uPU-specific overfitting; thus, we restrict evaluation to nnPU and nnPU+TRADES.
We set the TRADES coefficient to $\beta\in\{6,12,18\}$, and other adversarial-perturbation settings ($\epsilon$, $\alpha$, and the number of PGD iterations) follow Table~\ref{tab:exp_settings}.

% NOTE: CIFAR-100 / Alzheimer are evaluated only with nnPU variants (see Sec.~\ref{sec:main_results}).

\section{Main Results}\label{sec:main_results}

% ---------------------------------------------------------
% Main results (FMNIST / CIFAR-10)
% ---------------------------------------------------------
\begin{table}[t]
 \centering
    \caption{Main results on FashionMNIST (6-layer MLP) and CIFAR-10 (ResNet-18).
We compare uPU/nnPU and their adversarially trained variants (PGD training and TRADES training), and report clean accuracy (Clean) and adversarial accuracy (Adv.) under PGD attacks ($\epsilon$ follows Table~\ref{tab:exp_settings}, 10 steps) on the test set.
For each setting, we select the epoch that achieves the highest Clean Accuracy.
While uPU/nnPU without adversarial training achieve almost zero Adv., TRADES improves robustness without severely degrading clean accuracy.}
 \label{tab:main_results_fm_c10}
 \vspace{5pt}
 \small
 \setlength{\tabcolsep}{4.2pt}
 \begin{tabular}{l|cc|cc}
 \toprule
  \multirow{2}{*}{Method} & \multicolumn{2}{c|}{F-MNIST} & \multicolumn{2}{c}{CIFAR-10} \\
 \cline{2-5}
  & Clean & Adv. & Clean & Adv. \\
 \midrule
  uPU  & 0.937 & 0.190 & 0.850 & 0.114 \\
  nnPU  & \textbf{0.948} & 0.001 & \textbf{0.887} & 0.001 \\
  uPU-PGD  & 0.935  & 0.843  & 0.802  & 0.714  \\
  nnPU-PGD  & 0.930 & 0.860 & 0.732 & 0.686 \\
  uPU+TRADES  & 0.934 & 0.914 & 0.845 & 0.711 \\
  nnPU+TRADES & 0.944 & \textbf{0.928} & 0.850 & \textbf{0.723} \\
 \bottomrule
 \end{tabular}
\end{table}

% ---------------------------------------------------------
% Main results (CIFAR-100 / Alzheimer): nnPU variants only
% ---------------------------------------------------------
\begin{table}[t]
 \centering
    \caption{Main results on CIFAR-100 (ResNet-18) and Alzheimer MRI (ResNet-50) (nnPU variants only).
We compare clean accuracy (Clean) and adversarial accuracy (Adv.) under PGD attacks ($\epsilon$ follows Table~\ref{tab:exp_settings}, 10 steps) on the test set.
For each setting, we select the epoch that achieves the highest Clean Accuracy.
While nnPU alone attains almost zero Adv., nnPU+TRADES substantially improves robustness.}
 \label{tab:main_results_c100_ad}
 \vspace{5pt}
 \small
 \setlength{\tabcolsep}{4.2pt}
 \begin{tabular}{l|cc|cc}
 \toprule
  \multirow{2}{*}{Method} & \multicolumn{2}{c|}{CIFAR-100} & \multicolumn{2}{c}{Alzheimer} \\
 \cline{2-5}
  & Clean & Adv. & Clean & Adv. \\
 \midrule
  nnPU  & \textbf{0.680} & 0.001 & \textbf{0.683} & 0.000 \\
  nnPU+TRADES & 0.645 & \textbf{0.450} & 0.649 & \textbf{0.409} \\
 \bottomrule
 \end{tabular}
\end{table}

Tables~\ref{tab:main_results_fm_c10} and \ref{tab:main_results_c100_ad} report clean accuracy (Clean) and adversarial accuracy (Adv.) on each dataset.
First, while uPU and nnPU achieve high clean accuracy, their adversarial accuracy is extremely low, indicating vulnerability to perturbations.
In contrast, nnPU-PGD and (uPU/nnPU)+TRADES markedly improve adversarial accuracy, confirming gains in robustness.

Moreover, on F-MNIST and CIFAR-10, nnPU+TRADES consistently achieves higher adversarial accuracy than uPU+TRADES.
On the other hand, methods with adversarial training tend to suffer a drop in clean accuracy, revealing a trade-off between accuracy and robustness.
For CIFAR-100 and Alzheimer (Table~\ref{tab:main_results_c100_ad}), nnPU+TRADES maintains non-trivial adversarial accuracy while retaining reasonable clean accuracy on both datasets.

\begin{table}[t]
 \centering
    \caption{Ablation on the TRADES coefficient $\beta$ (F-MNIST / CIFAR-10).
We vary $\beta\in\{6,12,18\}$ and compare clean accuracy (Clean Acc.) and adversarial accuracy (Adv. Acc.) for uPU+TRADES and nnPU+TRADES.
On FashionMNIST, performance changes only mildly with $\beta$, whereas on CIFAR-10 increasing $\beta$ tends to improve adversarial accuracy at the cost of decreased clean accuracy.}
 \label{tab:beta_sweep}
 \vspace{5pt}
 \small
 \setlength{\tabcolsep}{4.0pt}
 \begin{tabular}{l|cc|cc}
 \toprule
  \multirow{2}{*}{Method} &
  \multicolumn{2}{c|}{F-MNIST} &
 \multicolumn{2}{c}{CIFAR-10} \\
 \cline{2-5}
  & Clean Acc. & Adv. Acc. & Clean Acc. & Adv. Acc. \\
 \midrule
  uPU+TRADES ($\beta=6$)  & 0.939 & 0.861 & 0.846 & 0.711 \\
  uPU+TRADES ($\beta=12$)  & 0.935 & 0.848 & 0.831 & 0.735 \\
  uPU+TRADES ($\beta=18$)  & 0.937 & 0.870 & 0.809 & 0.735 \\
  nnPU+TRADES ($\beta=6$)  & \textbf{0.944} & \textbf{0.877} & \textbf{0.861} & 0.723 \\
  nnPU+TRADES ($\beta=12$) & 0.933 & 0.875 & 0.845 & 0.740 \\
  nnPU+TRADES ($\beta=18$) & 0.930 & 0.871 & 0.836 & \textbf{0.743} \\
 \bottomrule
 \end{tabular}
\end{table}

Table~\ref{tab:beta_sweep} shows performance as we vary the TRADES coefficient $\beta$.
On CIFAR-10, adversarial accuracy tends to increase as $\beta$ becomes larger, while clean accuracy decreases step by step.
For example, for uPU+TRADES, increasing $\beta$ from 6 to 12 improves adversarial accuracy but reduces clean accuracy, and at $\beta=18$ the adversarial accuracy appears to saturate.
Similarly for nnPU+TRADES, increasing $\beta$ improves adversarial accuracy but also induces a decrease in clean accuracy, indicating that $\beta$ is a key factor controlling the accuracy--robustness trade-off.

On F-MNIST, the variation across $\beta$ is smaller than on CIFAR-10, and in particular uPU+TRADES exhibits only limited changes in clean accuracy even as $\beta$ increases.
However, for nnPU+TRADES, setting $\beta$ too large slightly degrades adversarial accuracy, suggesting that the optimal $\beta$ may depend on the dataset and the learning scheme (uPU vs. nnPU).

% ---------------------------------------------------------
% Additional experiments for validating theoretical analysis (n_U threshold)
% ---------------------------------------------------------
\section{Validation of Theoretical Analysis}\label{subsec:validate_theory}

\paragraph{Objective.}
In Chapter~\ref{ch:theory}, as a condition under which PU learning can become advantageous compared to supervised learning (PN),
we compared the upper bounds on the estimation error of PN-TRADES and PU+TRADES,
and derived a threshold on the number of unlabeled samples, $n_{\mathrm U}^{\star}$, which holds when the upper bound for PN-TRADES exceeds that of PU+TRADES (Theorem~\ref{thm:nu-threshold-trades}).
The aim of this section is to examine to what extent this theoretical threshold aligns with experimental results as a qualitative guideline:
``increasing the amount of unlabeled data can make PU methods preferable.''
Note that the theoretical threshold is a sufficient condition based on upper-bound comparison; therefore, we do not generally expect it to exactly match the empirical turning point.

\paragraph{Validation procedure.}
We validate the theory in three steps:
(i) substitute constants into the theoretical expression to obtain a numerical value of $n_{\mathrm U}^{\star}$;
(ii) sweep $n_{\mathrm U}$ over discrete values and compare the test losses of PU+TRADES and PN-TRADES;
(iii) compare the empirical turning point $\widehat n_{\mathrm U}^{\mathrm{emp}}$ with $n_{\mathrm U}^{\star}$ and discuss reasons for the discrepancy.

% ---------------------------
% 1) Numerically instantiating n_U^*
% ---------------------------
\paragraph{Numerical instantiation of the theoretical threshold $n_{\mathrm U}^{\star}$.}
The theoretical expression contains an upper bound on the weight norm $W$ (i.e., $\|w\|_2\le W$), but the threshold used here is based on comparing estimation-error upper bounds.
We define the norm upper bound of the perturbed input as
\begin{equation}
C_x^{\mathrm{adv}} := C_x+\varepsilon d^{1/q},
\qquad
C_{\mathrm{KL}} := W C_x^{\mathrm{adv}} = W(C_x+\varepsilon d^{1/q})
\label{eq:ckl_def}
\end{equation}
and approximate an upper bound of the logistic loss by $C_\ell\approx W C_x$.
Then we can rewrite $\Gamma_\delta\approx W\,\overline{\Gamma}_\delta$, and factor out $W$ from both sides of the comparison inequality.
As a result, the numerical instantiation of the threshold simplifies to a form independent of $W$.

Below we show intermediate steps to obtain $\Gamma_\delta\approx W\,\overline{\Gamma}_\delta$.
The quantity $\Gamma_\delta$ defined in Theorem~\ref{thm:nu-threshold-trades} is
\begin{align}
\Gamma_\delta
&=
4\big(L_\ell+4\beta L_{\mathrm{KL}}\big)\,W C_x d^{1/q}
+8\beta L_{\mathrm{KL}}\,\varepsilon W d^{1/q}
+\kappa_\delta\,(C_\ell+\beta C_{\mathrm{KL}})
\label{eq:Gamma_step0_exp}
\\
&\approx
4\big(L_\ell+4\beta L_{\mathrm{KL}}\big)\,W C_x d^{1/q}
+8\beta L_{\mathrm{KL}}\,\varepsilon W d^{1/q}
+\kappa_\delta\,(W C_x+\beta W C_x^{\mathrm{adv}})
\label{eq:Gamma_step1_exp}
\\
&=
4\big(L_\ell+4\beta L_{\mathrm{KL}}\big)\,W C_x d^{1/q}
+8\beta L_{\mathrm{KL}}\,\varepsilon W d^{1/q}
+\kappa_\delta\,W\big(C_x+\beta C_x^{\mathrm{adv}}\big)
\label{eq:Gamma_step2_exp}
\\
&=
W\Big\{
4\big(L_\ell+4\beta L_{\mathrm{KL}}\big)\,C_x d^{1/q}
+8\beta L_{\mathrm{KL}}\,\varepsilon d^{1/q}
+\kappa_\delta\big(C_x+\beta C_x^{\mathrm{adv}}\big)
\Big\}
\label{eq:Gamma_step3_exp}
\\
&=: W\,\overline{\Gamma}_\delta .
\label{eq:Gamma_step4_exp}
\end{align}

Specifically, letting
\begin{equation}
\kappa_\delta:=\sqrt{2\ln\frac{2}{\delta}},
\qquad
\overline{\Gamma}_\delta
:=
4\big(L_\ell+4\beta L_{\mathrm{KL}}\big) C_x d^{1/q}
+8\beta L_{\mathrm{KL}}\varepsilon d^{1/q}
+\kappa_\delta\big(C_x+\beta C_x^{\mathrm{adv}}\big)
\label{eq:Gamma_bar_def}
\end{equation}
the feasibility condition \eqref{eq:compare-pn-uputr-feasible} in Theorem~\ref{thm:nu-threshold-trades} becomes
\begin{equation}
\overline{\Gamma}_\delta\frac{\pi_{\mathrm N}}{\sqrt{n_{\mathrm N}}}
\ >\
\frac{\pi_{\mathrm P}}{\sqrt{n_{\mathrm P}}}\Big(4L_\ell\,C_x d^{1/q}+\kappa_\delta C_x\Big),
\label{eq:compare-pn-uputr-feasible-exp}
\end{equation}
and under this condition we obtain
\begin{equation}
\boxed{\
\ n_{\mathrm U}
\ >\
\left(
\frac{\overline{\Gamma}_\delta}
{\overline{\Gamma}_\delta\frac{\pi_{\mathrm N}}{\sqrt{n_{\mathrm N}}}
-\frac{\pi_{\mathrm P}}{\sqrt{n_{\mathrm P}}}\big(4L_\ell\,C_x d^{1/q}+\kappa_\delta C_x\big)}
\right)^{\!2}
\ }
\label{eq:nu_threshold_exp_simplified}
\end{equation}
When this condition is satisfied, comparing the estimation-error upper bounds of PN-TRADES and PU+TRADES shows that the upper bound for PN-TRADES exceeds that of PU+TRADES.
That is, in theory, beyond this threshold PU+TRADES (uPU/nnPU) can become preferable to PN-TRADES.

\paragraph{Constants and settings.}
The main symbols and constants used for numerical instantiation are summarized in Table~\ref{tab:validate_theory_constants}.
In this section we use $q=2$, and for the input norm bound we set $C_x=\sqrt{d}$ (i.e., $\|x\|_2\le \sqrt{d}$).
Since $d^{1/q}=\sqrt{d}$, we have
\begin{equation}
C_x d^{1/q}=\sqrt d\cdot \sqrt d=d.
\label{eq:cx_d_simplify}
\end{equation}
Thus, we substitute $d=784$ for F-MNIST and $d=3072$ for CIFAR-10.

\begin{table}[t]
 \centering
  \caption{Constants used to numerically instantiate the theoretical threshold $n_{\mathrm U}^{\star}$ derived in Theorem~\ref{thm:nu-threshold-trades} (FashionMNIST / CIFAR-10).
We follow Table~\ref{tab:exp_settings} for the class priors and sample sizes, and summarize the input dimension $d$, norm bounds $C_x, C_x^{\mathrm{adv}}$, Lipschitz constants $L_\ell, L_{\mathrm{KL}}$, confidence level $\delta$, and so on.}
 \label{tab:validate_theory_constants}
 \vspace{4pt}
 \small
 \setlength{\tabcolsep}{4pt}
 \begin{tabular}{l l c c l}
 \toprule
  \textbf{Symbol} & \textbf{Meaning} & \textbf{FashionMNIST} & \textbf{CIFAR-10} & \textbf{Remarks} \\
 \midrule
  $\pi_{\mathrm P}$ & prior of the positive class & $0.4$ & $0.4$ & assumption \\
  $\pi_{\mathrm N}$ & prior of the negative class & $0.6$ & $0.6$ & $\pi_{\mathrm N}=1-\pi_{\mathrm P}$ \\
  $n_{\mathrm P}$ & \# positive samples & $1000$ & $1000$ & given setting \\
  $n_{\mathrm N}$ & \# negative samples & $500$ & $500$ & given setting \\
  $\beta$ & TRADES coefficient & $6$ & $6$ & representative value \\
  $\epsilon$ & perturbation radius & $0.3$ & $0.031$ & experimental setting (attack radius) \\
  $q$ & norm index & $2$ & $2$ & dual norm of $p=2$ \\
  $d$ & input dimension & $784$ & $3072$ & $1\times 28\times 28$, $3\times 32\times 32$ \\
  $C_x$ & input norm bound & $\sqrt d$ & $\sqrt d$ & $\|x\|_2\le \sqrt d$ \\
  $C_x^{\mathrm{adv}}$ & perturbed-input bound & $C_x+\epsilon d^{1/q}$ & $C_x+\epsilon d^{1/q}$ & from \eqref{eq:ckl_def} \\
  $L_\ell$ & Lipschitz constant of loss & $1$ & $1$ & logistic loss \\
  $L_{\mathrm{KL}}$ & Lipschitz constant of KL term & $1$ & $1$ & setting in Chapter~\ref{ch:theory} \\
  $\delta$ & confidence level & $0.05$ & $0.05$ & fixed \\
 \bottomrule
 \end{tabular}
\end{table}

Substituting the above settings into \eqref{eq:nu_threshold_exp_simplified}, we obtain
\[
n_{\mathrm U}^{\star}(\mathrm{F\text{-}MNIST})
\approx 1443.37
\ (\Rightarrow\ n_{\mathrm U}\ge 1444),
\]
\[
n_{\mathrm U}^{\star}(\mathrm{CIFAR\text{-}10})
\approx 1443.25
\ (\Rightarrow\ n_{\mathrm U}\ge 1444).
\]

% ---------------------------
% 2) Experimental protocol
% ---------------------------
\paragraph{Experimental protocol for validation.}
Since the theoretical comparison concerns estimation error (risk), in this section we use the loss on the test set as a proxy.
Specifically, for each $n_{\mathrm U}$, let
\(
t^{\star}(n_{\mathrm U})
\)
denote the epoch achieving the highest Clean Accuracy, and we compare the sum of the clean loss and adversarial loss at that epoch:
\begin{equation}
\mathcal{L}_{\mathrm{sum}}(n_{\mathrm U})
:=
\mathcal{L}_{\mathrm{clean}}\big(t^{\star}(n_{\mathrm U});n_{\mathrm U}\big)
+
\mathcal{L}_{\mathrm{adv}}\big(t^{\star}(n_{\mathrm U});n_{\mathrm U}\big).
\label{eq:loss_sum_def}
\end{equation}
Here, $\mathcal{L}_{\mathrm{clean}}$ is the clean loss on the test set, and $\mathcal{L}_{\mathrm{adv}}$ is the adversarial loss computed on adversarial examples generated from the same test set.
We consider the following settings: (a) FMNIST: 6-layer MLP and a linear model; (b) CIFAR-10: a linear model and ResNet-18.
For each setting, we train PU+TRADES and PN-TRADES and compare how $\mathcal{L}_{\mathrm{sum}}$ changes with $n_{\mathrm U}$.

\paragraph{Empirical turning point.}
To relate to the theoretical threshold $n_{\mathrm U}^{\star}$, we define the empirical turning point as the smallest $n_{\mathrm U}$ at which the sign of
\[
\Delta(n_{\mathrm U})
:=
\mathcal{L}_{\mathrm{sum}}^{\mathrm{PU\text{-}TRADES}}(n_{\mathrm U})
-
\mathcal{L}_{\mathrm{sum}}^{\mathrm{PN\text{-}TRADES}}(n_{\mathrm U})
\]
becomes negative.
Moreover, if the sign of $\Delta$ flips between $n_{\mathrm U}=U_k$ and $U_{k+1}$, we estimate the turning point by linear interpolation:
\begin{equation}
\widehat n_{\mathrm U}^{\mathrm{emp}}
:=
U_k
+
\frac{-\Delta(U_k)}{\Delta(U_{k+1})-\Delta(U_k)}(U_{k+1}-U_k).
\label{eq:nu_emp_def}
\end{equation}

% ---------------------------
% 3) Results
% ---------------------------
\paragraph{Results.}
Figure~\ref{fig:validate_theory_loss_sum} shows the trajectories of $\mathcal{L}_{\mathrm{sum}}$ as a function of $n_{\mathrm U}$.
The orange curve represents $\mathcal{L}_{\mathrm{sum}}(n_{\mathrm U})$ for PU+TRADES, the dashed gray line is the baseline value for PN-TRADES,
and the blue vertical line indicates the theoretical threshold $n_{\mathrm U}^{\star}$.
When a crossing is observed within the sweep range, we mark $\widehat n_{\mathrm U}^{\mathrm{emp}}$ estimated by \eqref{eq:nu_emp_def} as a point in the figure.

\begin{figure}[t]
 \centering
 \begin{minipage}{0.48\linewidth}
 \centering
 \includegraphics[width=\linewidth]{fmnist_linear2.undefined.pdf}
 \caption*{(a) FMNIST / Linear}
 \end{minipage}\hfill
 \begin{minipage}{0.48\linewidth}
 \centering
 \includegraphics[width=\linewidth]{fmnist_6lMLP2.undefined.pdf}
 \caption*{(b) FMNIST / 6-layer MLP}
 \end{minipage}

 \vspace{0.5em}

 \begin{minipage}{0.48\linewidth}
 \centering
 \includegraphics[width=\linewidth]{cifar10_linear.undefined.pdf}
 \caption*{(c) CIFAR-10 / Linear}
 \end{minipage}\hfill
 \begin{minipage}{0.48\linewidth}
 \centering
 \includegraphics[width=\linewidth]{cifar10_resnet.undefined.pdf}
 \caption*{(d) CIFAR-10 / ResNet-18}
 \end{minipage}
  \caption{Validation results for the theoretical threshold $n_{\mathrm U}^{\star}$ of the unlabeled sample size derived in our theoretical analysis.
Each panel plots the test loss sum for PU+TRADES,
$\mathcal{L}_{\mathrm{sum}}(n_{\mathrm U})=\mathcal{L}_{\mathrm{clean}}(t^{\star}(n_{\mathrm U});n_{\mathrm U})+\mathcal{L}_{\mathrm{adv}}(t^{\star}(n_{\mathrm U});n_{\mathrm U})$ (Eq.~\eqref{eq:loss_sum_def}),
against $n_{\mathrm U}$, and compares it with the PN-TRADES baseline value (which does not depend on $n_{\mathrm U}$).
Here, $t^{\star}(n_{\mathrm U})$ denotes the epoch achieving the highest Clean Accuracy.
The intersection $\widehat n_{\mathrm U}^{\mathrm{emp}}$ is estimated by linear interpolation.}
 \label{fig:validate_theory_loss_sum}
\end{figure}

\begin{table}[t]
 \centering
  \caption{Comparison between the theoretical threshold $n_{\mathrm U}^{\star}$ (Theorem~\ref{thm:nu-threshold-trades}) and the empirical turning point $\widehat n_{\mathrm U}^{\mathrm{emp}}$.
$\widehat n_{\mathrm U}^{\mathrm{emp}}$ is estimated by linear interpolation from Fig.~\ref{fig:validate_theory_loss_sum} as the value of $n_{\mathrm U}$ where the loss sums $\mathcal{L}_{\mathrm{sum}}$ of PU+TRADES and PN-TRADES coincide.
``---'' indicates that no intersection existed within the range of $n_{\mathrm U}$ evaluated in this study.}
 \label{tab:validate_theory_summary}
 \begin{tabular}{lcc}
 \toprule
  Setting & $n_{\mathrm U}^{\star}$ (theory) & $\widehat n_{\mathrm U}^{\mathrm{emp}}$ (emp.) \\
 \midrule
  FMNIST / 6-layer MLP & 1444 & 4788.14 \\
  FMNIST / Linear  & 1444 & 4247.13 \\
  CIFAR-10 / Linear  & 1444 & 2750.00 \\
  CIFAR-10 / ResNet-18  & 1444 & --- \\
 \bottomrule
 \end{tabular}
\end{table}

\paragraph{Discussion.}
From Fig.~\ref{fig:validate_theory_loss_sum} and Table~\ref{tab:validate_theory_summary}, for F-MNIST (both the linear model and the 6-layer MLP),
$\mathcal{L}_{\mathrm{sum}}(n_{\mathrm U})$ decreases as $n_{\mathrm U}$ increases, and the intersection where the loss sums of PU+TRADES and PN-TRADES coincide is estimated as
$\widehat n_{\mathrm U}^{\mathrm{emp}}\approx 4247.13$ (linear model) and $\widehat n_{\mathrm U}^{\mathrm{emp}}\approx 4788.14$ (6-layer MLP).
These values are larger than the theoretical threshold $n_{\mathrm U}^{\star}=1444$,
which is consistent with the fact that $n_{\mathrm U}^{\star}$ is a sufficient condition derived from upper-bound comparison (and hence can be conservative).

For CIFAR-10, the results depend on the model:
(i) \textbf{CIFAR-10 / Linear}:
a crossing is observed at $\widehat n_{\mathrm U}^{\mathrm{emp}}\approx 2750.00$ (between $U=2000$ and $3000$).
(ii) \textbf{CIFAR-10 / ResNet-18}:
using the PN baseline value $1.1604$, the PU loss sum remains smaller throughout the range $U=1000$--$10000$,
and thus there is no intersection within this range (i.e., PU is already better at the smallest observed value $U=1000$).
Overall, while the theoretical threshold $n_{\mathrm U}^{\star}$ is not an exact predictor of the intersection location,
the experiments also indicate that with sufficiently many unlabeled samples, PU methods can outperform PN methods.
