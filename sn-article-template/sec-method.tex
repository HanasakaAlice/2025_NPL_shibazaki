\section{Accurate and Robust PU Learning}\label{ch:method}

% ========================================================================

In this section, we first clarify the issues that arise when uPU learning is naively combined with PGD-based adversarial training.
We then propose a new learning method, PU+TRADES, which adapts the TRADES framework to PU learning.

\subsection{uPU+PGD}

In uPU learning, the empirical risk $\widehat{R}_{\mathrm{uPU}}(g)$ is estimated by minimizing
\begin{align}
\widehat{R}_{\mathrm{uPU}}(g)
= \frac{\pi_{\mathrm{P}}}{n_{\mathrm{P}}}
\sum_{i=1}^{n_{\mathrm{P}}}
\tilde{\ell}\left(g\bigl(\boldsymbol{x}_i^{\mathrm{P}}\bigr),+1\right)
+ \frac{1}{n_{\mathrm{U}}}
\sum_{i=1}^{n_{\mathrm{U}}}
\ell\left(g\bigl(\boldsymbol{x}_i^{\mathrm{U}}\bigr),-1\right).
\end{align}
Here, the loss is taken differently for P and U samples, which can be summarized as
\begin{align}
\mathscr{L}(\boldsymbol{x}):=
\begin{cases}
\tilde{\ell}(g(\boldsymbol{x}), +1), & \boldsymbol{x} \in \mathscr{X}_{\mathrm{P}},\\[2pt]
\ell(g(\boldsymbol{x}), -1),         & \boldsymbol{x} \in \mathscr{X}_{\mathrm{U}}.
\end{cases}
\label{eq:uPU_loss_piecewise}
\end{align}
Using this loss $\mathscr{L}$, we generate an adversarial example for each sample via PGD.
A single PGD update step is given by
\begin{align}
\boldsymbol{x}^{\prime} \leftarrow
\operatorname{Clip}_{(\boldsymbol{x}-\epsilon,\ \boldsymbol{x}+\epsilon)}
\Bigl[\boldsymbol{x}^{\prime}+\alpha\,\operatorname{sign}\!\bigl(\nabla_{\boldsymbol{x}^{\prime}} \mathscr{L}(\boldsymbol{x}^{\prime})\bigr)\Bigr].
\end{align}

\subsection*{Issues with uPU+PGD}

In uPU, the loss for unlabeled data is computed as if the label were always $y=-1$.
However, in reality, the unlabeled set contains a mixture of positives and negatives.
This property is incompatible with PGD-based adversarial training.

\begin{itemize}
  \item \textbf{Negative U samples.}
  Since the loss $\ell(g(\boldsymbol{x}^{\mathrm{U}}), -1)$ is consistent with the true label, it pushes the input in a direction that increases the loss for the negative class.
  Consequently, PGD generates appropriate adversarial perturbations, contributing to improved robustness.

  \item \textbf{Positive U samples.}
  If perturbations are generated using $\ell(g(\boldsymbol{x}^{\mathrm{U}}), -1)$ even though the sample is truly positive, PGD updates the input so as to maximize the \emph{negative-class} loss.
  As a result, the input may be pushed not toward the decision boundary, but rather toward a region where it is classified as positive with higher confidence.
  Therefore, PGD fails to produce perturbations in the “most misclassifiable direction,” and the training can break down.
\end{itemize}

Hence, to generate adversarial perturbations appropriately in PU learning, it is essential to use a \emph{label-independent} perturbation generation mechanism.
This motivates PU+TRADES, introduced in the next section.

% ----------------------------------------------------------

\subsection{PU+TRADES}

In this work, we propose \textbf{uPU+TRADES} and \textbf{nnPU+TRADES}, which integrate TRADES into uPU and nnPU, respectively.
By introducing the TRADES framework into PU learning, we endow the model with robustness.

The objective function of uPU+TRADES is given by
\begin{equation}
\min_{g}\left[
\widehat{R}_{\mathrm{uPU}}(g)
+\beta \cdot \frac{1}{n} \sum_{i=1}^n
\max_{\left\|\boldsymbol{x}^{\prime}-\boldsymbol{x}_i\right\|_{\infty} \leq \epsilon}
\ell_{\mathrm{KL}}\left(g\left(\boldsymbol{x}_i\right)\ \|\ g\left(\boldsymbol{x}^{\prime}\right)\right)
\right],
\end{equation}
and the objective function of nnPU+TRADES is given by
\begin{equation}
\min_{g}\left[
\widehat{R}_{\mathrm{nnPU}}(g)
+\beta \cdot \frac{1}{n} \sum_{i=1}^n
\max_{\left\|\boldsymbol{x}^{\prime}-\boldsymbol{x}_i\right\|_{\infty} \leq \epsilon}
\ell_{\mathrm{KL}}\left(g\left(\boldsymbol{x}_i\right)\ \|\ g\left(\boldsymbol{x}^{\prime}\right)\right)
\right].
\end{equation}

In binary classification, the network outputs a one-dimensional logit $g(\boldsymbol{x};\boldsymbol{\theta})$.
We convert it into a Bernoulli probability vector and compute the KL divergence:
\begin{align}
p(\boldsymbol{x})=
\bigl[\sigma(g(\boldsymbol{x}; \boldsymbol{\theta})),\, 1-\sigma(g(\boldsymbol{x}; \boldsymbol{\theta}))\bigr],
\end{align}
where $\sigma(\cdot)$ denotes the sigmoid function.
The KL loss is then defined as
\begin{equation}
\begin{aligned}
\ell_{\mathrm{KL}}\left(g\left(\boldsymbol{x}_i; \boldsymbol{\theta}\right), g\left(\boldsymbol{x}_i^{\prime}; \boldsymbol{\theta}\right)\right)
&= \mathrm{KL}\bigl(p(\boldsymbol{x}_i)\,\|\,p(\boldsymbol{x}_i^{\prime})\bigr) \\
&= \sum_{c \in \{0,1\}} p_c(\boldsymbol{x}_i)\,
\log \frac{p_c(\boldsymbol{x}_i)}{p_c(\boldsymbol{x}_i^{\prime})}.
\end{aligned}
\end{equation}

This term encourages the model outputs to remain stable under small perturbations of $\boldsymbol{x}_i$,
thereby providing robustness against adversarial perturbations.





